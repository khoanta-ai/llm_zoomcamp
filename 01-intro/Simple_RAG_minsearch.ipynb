{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2bee8ff2-6e36-4e4a-9086-cd13b4fe8934",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-20 06:23:51--  https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3832 (3.7K) [text/plain]\n",
      "Saving to: ‘minsearch.py.2’\n",
      "\n",
      "minsearch.py.2      100%[===================>]   3.74K  --.-KB/s    in 0s      \n",
      "\n",
      "2024-06-20 06:23:52 (23.3 MB/s) - ‘minsearch.py.2’ saved [3832/3832]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Download minsearch.py\n",
    "!wget https://raw.githubusercontent.com/alexeygrigorev/minsearch/main/minsearch.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0b97917-b310-4d38-9747-ddede607e446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-20 06:23:52--  https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 658332 (643K) [text/plain]\n",
      "Saving to: ‘documents.json.1’\n",
      "\n",
      "documents.json.1    100%[===================>] 642.90K  --.-KB/s    in 0.006s  \n",
      "\n",
      "2024-06-20 06:23:53 (101 MB/s) - ‘documents.json.1’ saved [658332/658332]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Download documents.json\n",
    "!wget https://raw.githubusercontent.com/DataTalksClub/llm-zoomcamp/main/01-intro/documents.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b30527a8-0da1-4426-82d7-7833c29352c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import minsearch\n",
    "from openai import OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f2d09bd-61a6-418e-8f26-962cfdf68b81",
   "metadata": {},
   "source": [
    "![rag_chart.png](./imgs/rag_chart.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dce00bc-1ab0-4abf-b826-ae355dc34524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "746de48a-057b-43f3-9819-39230b19254b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_documents_from_json(json_path):\n",
    "    '''\n",
    "    Convert document json format to a list of\n",
    "    elements which contain 4 objects: \n",
    "    course, text, question, and section\n",
    "    '''\n",
    "    with open(json_path, 'rt') as f_in:\n",
    "        docs_raw = json.load(f_in) \n",
    "    documents = []\n",
    "    \n",
    "    for course_dict in docs_raw:\n",
    "        for doc in course_dict['documents']:\n",
    "            doc['course'] = course_dict['course']\n",
    "            documents.append(doc)\n",
    "    return documents\n",
    "\n",
    "\n",
    "def build_minsearch(text_fields, keyword_fields):\n",
    "    # SELECT * WHERE course = 'data-engineering-zoomcamp';\n",
    "    index = minsearch.Index(\n",
    "        text_fields=text_fields,\n",
    "        keyword_fields=keyword_fields\n",
    "    )\n",
    "    return index\n",
    "\n",
    "\n",
    "def build_db(documents, search_engine):\n",
    "    search_engine.fit(documents)\n",
    "\n",
    "\n",
    "def build_minsearch_engine(query, index, filter_dict, boost_dict, num_results):\n",
    "    results = index.search(\n",
    "        query=query,\n",
    "        filter_dict=filter_dict,\n",
    "        boost_dict=boost_dict,\n",
    "        num_results=num_results\n",
    "    )\n",
    "    return results\n",
    "\n",
    "\n",
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "QUESTION: {question}\n",
    "CONTEXT: {context}\n",
    "\"\"\".strip()\n",
    "    \n",
    "    context = \"\"\n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\"\n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt\n",
    "\n",
    "\n",
    "def build_llm(base_url, api_key):\n",
    "    client = OpenAI(\n",
    "        base_url=base_url,\n",
    "        api_key=api_key\n",
    "    )\n",
    "    return client\n",
    "\n",
    "\n",
    "def query_llm(prompt, client, model_name):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[{'role':'user', 'content':prompt}]\n",
    "    )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c12de24-4953-4a14-90b9-929d4c53a7ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 85.7 ms, sys: 0 ns, total: 85.7 ms\n",
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "query = 'how do I run kafka?'\n",
    "\n",
    "json_doc_path = 'documents.json'\n",
    "cvt_documents = build_documents_from_json(json_doc_path)\n",
    "# print(cvt_documents)\n",
    "\n",
    "text_fields = [\"question\", \"text\", \"section\"]\n",
    "keyword_fields = [\"course\"]\n",
    "minsearch_index = build_minsearch(text_fields, keyword_fields)\n",
    "\n",
    "build_db(cvt_documents, minsearch_index)\n",
    "\n",
    "filter_dict = {'course': 'data-engineering-zoomcamp'}\n",
    "boost_dict = {'question': 3.0, 'section': 0.5}\n",
    "num_results = 5\n",
    "minsearch_results = build_minsearch_engine(query=query, index=minsearch_index, \n",
    "                       filter_dict=filter_dict, boost_dict=boost_dict, \n",
    "                       num_results=num_results)\n",
    "\n",
    "prompt = build_prompt(query=query, search_results=minsearch_results)\n",
    "base_url = 'http://localhost:11434/v1/'\n",
    "api_key = 'ollama'\n",
    "model_name = 'phi3'\n",
    "phi3_client = build_llm(base_url, api_key)\n",
    "response_res = query_llm(prompt=prompt, client=phi3_client, model_name=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "28cdf43e-f255-46b9-a08c-25ece504119c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' In the project directory, to run Kafka with Java using your specific jar and code example, execute: `java -cp build/libs/<jar_name>-1.0-SNAPSHOT.jar:out src/main/java/org/example/JsonProducer.java`'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a263d073-6fe2-4bc3-b2bb-638b17a754ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def minsearch_rag(query):\n",
    "    minsearch_results = build_minsearch_engine(query=query, index=minsearch_index, \n",
    "                       filter_dict=filter_dict, boost_dict=boost_dict, \n",
    "                       num_results=num_results)\n",
    "    prompt = build_prompt(query=query, search_results=minsearch_results)\n",
    "    response_res = query_llm(prompt=prompt, client=phi3_client, model_name=model_name)\n",
    "    return response_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3c082702-e482-42e3-8283-3d79b8d6db66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Yes, even if you don't register before the course starts, you're still eligible to submit the homeworks and can follow the course at your own pace after it finishes as we will keep all the materials. However, there will be deadlines for turning in the final projects so avoid leaving everything till the last minute. You can also subscribe to our Google Calendar, join Telegram channel with announcements, register on DataTalks.Club's Slack and continue looking at homeworks while following the course after it finishes.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minsearch_rag(query= 'the course has already started, can I still enroll?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea9d6bd-6bfd-46c6-9d0a-5646717fd686",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
